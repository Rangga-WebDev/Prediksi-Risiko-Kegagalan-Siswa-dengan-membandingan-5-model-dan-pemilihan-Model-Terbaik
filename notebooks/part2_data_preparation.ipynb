{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6da9bd66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Do\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from category_encoders import TargetEncoder\n",
    "import joblib\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"Do\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b072fcf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset dimuat: (1044, 35)\n",
      "\n",
      "Distribusi target:\n",
      "   Lulus: 814 (78.0%)\n",
      "   Gagal: 230 (22.0%)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('../Dataset/DataGabungan.csv')\n",
    "print(f\"Dataset dimuat: {df.shape}\")\n",
    "print(f\"\\nDistribusi target:\")\n",
    "print(f\"   Lulus: {(df['risiko_gagal']==0).sum()} ({(df['risiko_gagal']==0).mean()*100:.1f}%)\")\n",
    "print(f\"   Gagal: {(df['risiko_gagal']==1).sum()} ({(df['risiko_gagal']==1).mean()*100:.1f}%)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "259f49c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Engineering\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'G2'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\AI Learn\\Chapter I\\.venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3811\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3812\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3813\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:167\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:196\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7096\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m: 'G2'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[32m      4\u001b[39m df[\u001b[33m'\u001b[39m\u001b[33mtotal_dukungan\u001b[39m\u001b[33m'\u001b[39m] = (\n\u001b[32m      5\u001b[39m     (df[\u001b[33m'\u001b[39m\u001b[33mdukungan_sekolah\u001b[39m\u001b[33m'\u001b[39m] == \u001b[33m'\u001b[39m\u001b[33mYa\u001b[39m\u001b[33m'\u001b[39m).astype(\u001b[38;5;28mint\u001b[39m) +\n\u001b[32m      6\u001b[39m     (df[\u001b[33m'\u001b[39m\u001b[33mdukungan_keluarga\u001b[39m\u001b[33m'\u001b[39m] == \u001b[33m'\u001b[39m\u001b[33mYa\u001b[39m\u001b[33m'\u001b[39m).astype(\u001b[38;5;28mint\u001b[39m) +\n\u001b[32m      7\u001b[39m     (df[\u001b[33m'\u001b[39m\u001b[33mles_pribadi\u001b[39m\u001b[33m'\u001b[39m] == \u001b[33m'\u001b[39m\u001b[33mYa\u001b[39m\u001b[33m'\u001b[39m).astype(\u001b[38;5;28mint\u001b[39m)\n\u001b[32m      8\u001b[39m )\n\u001b[32m     10\u001b[39m df[\u001b[33m'\u001b[39m\u001b[33mavg_parent_edu\u001b[39m\u001b[33m'\u001b[39m] = (df[\u001b[33m'\u001b[39m\u001b[33mpendidikan_ibu\u001b[39m\u001b[33m'\u001b[39m] + df[\u001b[33m'\u001b[39m\u001b[33mpendidikan_ayah\u001b[39m\u001b[33m'\u001b[39m]) / \u001b[32m2\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m df[\u001b[33m'\u001b[39m\u001b[33mprogression_G1_G2\u001b[39m\u001b[33m'\u001b[39m] = \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mG2\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m - df[\u001b[33m'\u001b[39m\u001b[33mG1\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m     13\u001b[39m df[\u001b[33m'\u001b[39m\u001b[33mprogression_G2_G3\u001b[39m\u001b[33m'\u001b[39m] = df[\u001b[33m'\u001b[39m\u001b[33mG3\u001b[39m\u001b[33m'\u001b[39m] - df[\u001b[33m'\u001b[39m\u001b[33mG2\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m     14\u001b[39m df[\u001b[33m'\u001b[39m\u001b[33mavg_progression\u001b[39m\u001b[33m'\u001b[39m] = (df[\u001b[33m'\u001b[39m\u001b[33mprogression_G1_G2\u001b[39m\u001b[33m'\u001b[39m] + df[\u001b[33m'\u001b[39m\u001b[33mprogression_G2_G3\u001b[39m\u001b[33m'\u001b[39m]) / \u001b[32m2\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\AI Learn\\Chapter I\\.venv\\Lib\\site-packages\\pandas\\core\\frame.py:4113\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4111\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns.nlevels > \u001b[32m1\u001b[39m:\n\u001b[32m   4112\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._getitem_multilevel(key)\n\u001b[32m-> \u001b[39m\u001b[32m4113\u001b[39m indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4114\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[32m   4115\u001b[39m     indexer = [indexer]\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\AI Learn\\Chapter I\\.venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3819\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3814\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   3815\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc.Iterable)\n\u001b[32m   3816\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[32m   3817\u001b[39m     ):\n\u001b[32m   3818\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[32m-> \u001b[39m\u001b[32m3819\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   3820\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   3821\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[32m   3822\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[32m   3823\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[32m   3824\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n",
      "\u001b[31mKeyError\u001b[39m: 'G2'"
     ]
    }
   ],
   "source": [
    "## 3.2 Feature Engineering\n",
    "print(\"Feature Engineering\")\n",
    "\n",
    "df['total_dukungan'] = (\n",
    "    (df['dukungan_sekolah'] == 'Ya').astype(int) +\n",
    "    (df['dukungan_keluarga'] == 'Ya').astype(int) +\n",
    "    (df['les_pribadi'] == 'Ya').astype(int)\n",
    ")\n",
    "\n",
    "df['avg_parent_edu'] = (df['pendidikan_ibu'] + df['pendidikan_ayah']) / 2\n",
    "\n",
    "df['perkembangan_G1_G2'] = df['nilai_periode2'] - df['nilai_periode1']\n",
    "df['perkembangan_G2_G3'] = df['nilai_akhir'] - df['nilai_periode2']\n",
    "df['rata_rata_Perkemvbangan'] = (df['perkembangan_G1_G2'] + df['perkembangan_G2_G3']) / 2\n",
    "\n",
    "df['ketidakhadiran_tinggi'] = (df['ketidakhadiran'] > df['ketidakhadiran'].quantile(0.75)).astype(int)\n",
    "df['waktu_belajar_rendah'] = (df['waktu_belajar'] <= 2).astype(int)\n",
    "df['ada_kegagalan'] = (df['jumlah_kegagalan'] > 0).astype(int)\n",
    "\n",
    "df['skor_gaya_hidup'] = (\n",
    "    (5 - df['konsumsi_alkohol_harian']) + (5 - df['konsumsi_alkohol_akhir_pekan']) +\n",
    "    df['kesehatan'] + (5 - df['keluar_dengan_teman']) + df['waktu_belajar']\n",
    ") / 5\n",
    "\n",
    "df['stabilitas_keluarga'] = (\n",
    "    (df['hubungan_keluarga'] >= 4).astype(int) +\n",
    "    (df['status_orangtua'] == 'Tinggal bersama').astype(int)\n",
    ")\n",
    "\n",
    "df['akses_dukungan'] = (\n",
    "    (df['internet_rumah'] == 'Ya').astype(int) +\n",
    "    (df['dukungan_sekolah'] == 'Ya').astype(int) +\n",
    "    (df['dukungan_keluarga'] == 'Ya').astype(int)\n",
    ")\n",
    "\n",
    "print(f\"seles\")\n",
    "print(f\"   Fitur baru: {len(df.columns) - 33}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8246319d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## 3.4 Encoding Kategorikal\n",
    "print(\"Encoding variabel kategorikal\")\n",
    "\n",
    "X = df.drop(['risiko_gagal', 'nilai_akhir'], axis=1)\n",
    "y = df['risiko_gagal']\n",
    "\n",
    "categorical_cols = X.select_dtypes(include='object').columns.tolist()\n",
    "print(f\"   Kolom kategorikal: {len(categorical_cols)}\")\n",
    "\n",
    "binary_cols = [\n",
    "    'dukungan_sekolah', 'dukungan_keluarga', 'les_pribadi',\n",
    "    'kegiatan_ekstra', 'tk', 'pendidikan_tinggi',\n",
    "    'internet_rumah', 'pacaran'\n",
    "]\n",
    "\n",
    "for col in binary_cols:\n",
    "    if col in X.columns:\n",
    "        X[col + '_binary'] = (X[col] == 'yes').astype(int)\n",
    "\n",
    "label_encoders = {}\n",
    "label_encode_cols = [\n",
    "    'sekolah', 'jenis_kelamin', 'tipe_alamat',\n",
    "    'ukuran_keluarga', 'status_ortu', 'wali', 'subject'\n",
    "]\n",
    "\n",
    "for col in label_encode_cols:\n",
    "    if col in X.columns:\n",
    "        le = LabelEncoder()\n",
    "        X[col + '_encoded'] = le.fit_transform(X[col].astype(str))\n",
    "        label_encoders[col] = le\n",
    "\n",
    "target_encoders = {}\n",
    "target_encode_cols = ['pekerjaan_ibu', 'pekerjaan_ayah', 'alasan_sekolah']\n",
    "\n",
    "for col in target_encode_cols:\n",
    "    if col in X.columns:\n",
    "        te = TargetEncoder(cols=[col])\n",
    "        X[col + '_encoded'] = te.fit_transform(X[col], y)\n",
    "        target_encoders[col] = te\n",
    "\n",
    "cols_to_drop = categorical_cols + binary_cols\n",
    "X = X.drop(columns=[c for c in cols_to_drop if c in X.columns])\n",
    "\n",
    "print(f\"Encoding selesai: {len(X.columns)} fitur numerik\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ecdcc3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 3.5 Seleksi Fitur\n",
    "\n",
    "print(\"Menghapus fitur berkorelasi tinggi\")\n",
    "\n",
    "corr_matrix = X.corr().abs()\n",
    "upper_triangle = corr_matrix.where(\n",
    "    np.triu(np.ones(corr_matrix.shape), k=1).astype(bool)\n",
    ")\n",
    "\n",
    "to_drop = [col for col in upper_triangle.columns \n",
    "           if any(upper_triangle[col] > 0.95)]\n",
    "\n",
    "print(f\"   Fitur dengan korelasi >0.95: {len(to_drop)}\")\n",
    "X = X.drop(columns=to_drop)\n",
    "print(f\"Fitur akhir: {len(X.columns)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dddaf210",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 3.7 Train-Test Split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(\"TTS:\")\n",
    "print(f\"   Training: {len(X_train)} ({len(X_train)/len(X)*100:.1f}%)\")\n",
    "print(f\"   Test: {len(X_test)} ({len(X_test)/len(X)*100:.1f}%)\")\n",
    "print(f\"\\n   Train - Lulus: {(y_train==0).sum()} ({(y_train==0).mean()*100:.1f}%)\")\n",
    "print(f\"   Train - Gagal: {(y_train==1).sum()} ({(y_train==1).mean()*100:.1f}%)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e4990c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## 3.8 Feature Scaling\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "X_train_scaled = pd.DataFrame(X_train_scaled, columns=X_train.columns, index=X_train.index)\n",
    "X_test_scaled = pd.DataFrame(X_test_scaled, columns=X_test.columns, index=X_test.index)\n",
    "\n",
    "print(\"StandardScaler\")\n",
    "print(f\"   Mean: {X_train_scaled.mean().mean():.2e}\")\n",
    "print(f\"   Std: {X_train_scaled.std().mean():.2f}\")\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "axes[0].boxplot(X_train[['nilai_periode1', 'nilai_periode2', 'ketidakhadiran']].values)\n",
    "axes[0].set_xticklabels(['nilai_periode1', 'nilai_periode2', 'ketidakhadiran'])\n",
    "axes[0].set_title('Sebelum Scaling', fontweight='bold')\n",
    "axes[0].set_ylabel('Nilai')\n",
    "\n",
    "axes[1].boxplot(X_train_scaled[['nilai_periode1', 'nilai_periode2', 'ketidakhadiran']].values)\n",
    "axes[1].set_xticklabels(['nilai_periode1', 'nilai_periode2', 'ketidakhadiran'])\n",
    "axes[1].set_title('Setelah Scaling', fontweight='bold')\n",
    "axes[1].set_ylabel('Nilai Standar')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e0f9e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 3.9 Simpan Dataset\n",
    "\n",
    "X_train_scaled.to_csv('../Dataset/X_train.csv', index=False)\n",
    "X_test_scaled.to_csv('../Dataset/X_test.csv', index=False)\n",
    "y_train.to_csv('../Dataset/y_train.csv', index=False, header=True)\n",
    "y_test.to_csv('../Dataset/y_test.csv', index=False, header=True)\n",
    "print(\"Dataset tersimpan:\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab444c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 3.10 Simpan Artifacts\n",
    "joblib.dump(scaler, '../models/scaler.pkl')\n",
    "joblib.dump(label_encoders, '../models/label_encoders.pkl')\n",
    "joblib.dump(target_encoders, '../models/target_encoders.pkl')\n",
    "joblib.dump(X_train.columns.tolist(), '../models/feature_cols.pkl')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
